{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise sheet 9 with the 5 Star Trek tv shows, and name of character. Load the data set into your console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "In moodle you will find the file trek.json and characters.csv. The first file contains tran- scripts of 5 Star Trek tv shows, separated into the individual episodes. \n",
    "\n",
    "The second file contains the name of characters, the tv show they appear in and their respective rank or role in the show.\n",
    "\n",
    "In this exercise, we will investigate, how well Word2Vec models the relationships between char- acters in the Star Trek franchise and how different window sizes can change the relationships that are being mapped by the model.\n",
    "\n",
    "Please note: The names “obrien” and “tpol” originally contained an apostrophe. For Word2Vec to recognize the characters correctly, you have to remove each apostrophe with an empty string!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (4.3.3)\n",
      "Requirement already satisfied: pandas in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (2.1.3)\n",
      "Requirement already satisfied: scipy in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: wrapt in /Users/oayanwale/Library/Python/3.9/lib/python/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim pandas scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.corpora import Dictionary\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "file_path = '/Users/oayanwale/Downloads/NLP_Exercise_24_25/Data'\n",
    "trek_json_file = f'{file_path}/trek.json'\n",
    "characters_csv_file = f'{file_path}/characters.csv'\n",
    "\n",
    "# Task 1: Load data from JSON and CSV files.\n",
    "with open(trek_json_file, 'r') as file:\n",
    "    transcripts = json.load(file)\n",
    "\n",
    "characters_df = pd.read_csv(characters_csv_file)\n",
    "\n",
    "# Preprocess character names by removing apostrophes.\n",
    "characters_df['Character'] = characters_df['Character'].str.replace(\"'\", \"\", regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2 best for this task\n",
    "\n",
    "data = pd.read_json(\"/Users/oayanwale/Downloads/NLP_Exercise_23/trek.json\")\n",
    "texts = data.values.flatten().tolist()  # Ensures all values are extracted as a list\n",
    "texts = [str(x) for x in texts if isinstance(x, str)]  # Ensure all values are strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "# Preprocess the texts so that they are fit for an analysis. \n",
    "# Argue the use the preprocessing steps you take for the given analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oayanwale/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/oayanwale/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Ensure stopwords are clean\n",
    "stop = {lemma.lemmatize(re.sub(r\"[^a-z]\", \"\", x)) for x in stop}\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove apostrophes to match Word2Vec format\n",
    "    text = text.replace(\"'\", \"\")\n",
    "\n",
    "    # Try to remove a date if present\n",
    "    date_match = re.search(r\"\\d{1,2}(th|st|nd|rd)? \\w+,? \\d{4}|\\w+ \\d{1,2}(th|st|nd|rd)?,? \\d{4}\", text)\n",
    "    if date_match:\n",
    "        text = text.split(date_match.group(0))[-1]  # Take everything after the date\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r\"[^a-z ]\", \" \", text)\n",
    "\n",
    "    # Tokenize and remove extra spaces\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Lemmatize and remove stopwords\n",
    "    tokens = [lemma.lemmatize(word) for word in tokens if word not in stop]\n",
    "\n",
    "    return tokens  # Return a list of tokens for Word2Vec\n",
    "\n",
    "# Apply preprocessing\n",
    "processed_texts = [preprocess(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Steps and Their Justifications\n",
    "Lowercasing Text:: Lowercasing the text helps in maintaining uniformity. This ensures that words considered the same semantically but differing in case (like \"Data\" and \"data\") are treated as identical. This is essential for word embeddings like Word2Vec, which are case-sensitive and could learn separate embeddings for the capitalized and the lowercase version of the same word.\n",
    "\n",
    "Removing Apostrophes: In the context of the given task, apostrophes might break the continuity of character names or create variations that are challenging to match consistently across dialogues. By removing them, we standardize character names ensuring that Word2Vec correctly identifies and groups them.\n",
    "\n",
    "Replacing Hyphens with Spaces:  Hyphens can connect words (e.g., \"long-term\" or \"Jean-Luc\") which might need to be interpreted separately by the model. Replacing hyphens with spaces splits compound words into their components, which can then be handled separately by the model. This helps in building more accurate word associations and embeddings.\n",
    "\n",
    "Tokenizing Text: Tokenizing the text (i.e., splitting it into individual words) is a critical step in preparing data for Word2Vec or any other word embedding model. These models require lists of words as input to learn the context and relationships between them.\n",
    "\n",
    "Summary\n",
    "The preprocessing steps are crucial for cleaning and standardizing the text data which directly impacts the quality and reliability of the Word2Vec embeddings. By converting text to lowercase, removing apostrophes, and replacing hyphens with spaces, we ensure that the names of characters and other textual data are uniformly represented. This helps in preventing the model from treating varying representations as different entities and ensures more accurate context and relationship modeling between words. Tokenization is fundamental as the Word2Vec model operates on tokenized words to learn their embeddings and contextual similarities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "# Train a Word2Vec model on all transcripts with a window size of two (i.e. two words in each direction) and a vector dimension of 300. \n",
    "# Train another model with the same parameters and only change the window size to ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train Word2Vec model with window size of two\n",
    "model1 = Word2Vec(processed_texts, vector_size=300, window=2, min_count=1, workers=4)\n",
    "\n",
    "# Train Word2Vec model with window size of ten\n",
    "model2 = Word2Vec(processed_texts, vector_size=300, window=10, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create dictionary and corpus using preprocessed tokens\n",
    "dictionary = Dictionary(processed_texts)\n",
    "corpus = [dictionary.doc2bow(script) for script in processed_texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "# We will now use the characters from characters.csv and see, how well Word2Vec differenti- ates the different tv shows. Calculate the cosine similarities of all possible character pairs for both models. \n",
    "\n",
    "# Then, calculate the average similarity between all character pairs within each tv show and the average pairwise similarity to all characters of a different tv show. In the end you should have a 5x5 matrix, containing average pairwise similarities between and within all 5 tv shows.\n",
    "\n",
    "# What do you notice? Which model does differentiate the characters of a tv show better from other tv shows?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Series</th>\n",
       "      <th>Roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archer</td>\n",
       "      <td>ENT</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kirk</td>\n",
       "      <td>TOS</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>picard</td>\n",
       "      <td>TNG</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sisko</td>\n",
       "      <td>DS9</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>janeway</td>\n",
       "      <td>VOY</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tucker</td>\n",
       "      <td>ENT</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scott</td>\n",
       "      <td>TOS</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>laforge</td>\n",
       "      <td>TNG</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>obrien</td>\n",
       "      <td>DS9</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>torres</td>\n",
       "      <td>VOY</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tpol</td>\n",
       "      <td>ENT</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spock</td>\n",
       "      <td>TOS</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>riker</td>\n",
       "      <td>TNG</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kira</td>\n",
       "      <td>DS9</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chakotay</td>\n",
       "      <td>VOY</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trip</td>\n",
       "      <td>ENT</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>scotty</td>\n",
       "      <td>TOS</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>beverly</td>\n",
       "      <td>TNG</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jadzia</td>\n",
       "      <td>DS9</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>harry</td>\n",
       "      <td>VOY</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character Series           Roles\n",
       "0     archer    ENT        Captains\n",
       "1       kirk    TOS        Captains\n",
       "2     picard    TNG        Captains\n",
       "3      sisko    DS9        Captains\n",
       "4    janeway    VOY        Captains\n",
       "5     tucker    ENT       Engineers\n",
       "6      scott    TOS       Engineers\n",
       "7    laforge    TNG       Engineers\n",
       "8     obrien    DS9       Engineers\n",
       "9     torres    VOY       Engineers\n",
       "10      tpol    ENT  First Officers\n",
       "11     spock    TOS  First Officers\n",
       "12     riker    TNG  First Officers\n",
       "13      kira    DS9  First Officers\n",
       "14  chakotay    VOY  First Officers\n",
       "15      trip    ENT       Nicknames\n",
       "16    scotty    TOS       Nicknames\n",
       "17   beverly    TNG       Nicknames\n",
       "18    jadzia    DS9       Nicknames\n",
       "19     harry    VOY       Nicknames"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "characters_df = pd.read_csv(characters_csv_file)\n",
    "characters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Character Series           Roles  \\\n",
      "0     archer    ENT        Captains   \n",
      "1       kirk    TOS        Captains   \n",
      "2     picard    TNG        Captains   \n",
      "3      sisko    DS9        Captains   \n",
      "4    janeway    VOY        Captains   \n",
      "5     tucker    ENT       Engineers   \n",
      "6      scott    TOS       Engineers   \n",
      "7    laforge    TNG       Engineers   \n",
      "8     obrien    DS9       Engineers   \n",
      "9     torres    VOY       Engineers   \n",
      "10      tpol    ENT  First Officers   \n",
      "11     spock    TOS  First Officers   \n",
      "12     riker    TNG  First Officers   \n",
      "13      kira    DS9  First Officers   \n",
      "14  chakotay    VOY  First Officers   \n",
      "15      trip    ENT       Nicknames   \n",
      "16    scotty    TOS       Nicknames   \n",
      "17   beverly    TNG       Nicknames   \n",
      "18    jadzia    DS9       Nicknames   \n",
      "19     harry    VOY       Nicknames   \n",
      "\n",
      "                                           Distances1  \\\n",
      "0   [0.0, 0.7208909048931522, 0.6895365561243276, ...   \n",
      "1   [0.7208909048931522, 0.0, 0.602005696738748, 0...   \n",
      "2   [0.6895365561243276, 0.602005696738748, 0.0, 0...   \n",
      "3   [0.7165056724639904, 0.7498883896616257, 0.682...   \n",
      "4   [0.581562694894215, 0.751643416771538, 0.73235...   \n",
      "5   [0.14767356552072242, 0.8188708407854127, 0.75...   \n",
      "6   [0.7091926809124438, 0.23459872804579274, 0.54...   \n",
      "7   [0.6726415100968977, 0.6631738705920972, 0.297...   \n",
      "8   [0.8335620431979512, 0.7771443828518045, 0.598...   \n",
      "9   [0.6813261979135298, 0.8037809152348383, 0.850...   \n",
      "10  [0.13605530235395358, 0.7811482818980454, 0.69...   \n",
      "11  [0.769839280293052, 0.15935224666960512, 0.606...   \n",
      "12  [0.6919519501710039, 0.7268224120439766, 0.138...   \n",
      "13  [0.7672236374444863, 0.8072818707614484, 0.778...   \n",
      "14  [0.6025535832402734, 0.8326290161276206, 0.835...   \n",
      "15  [0.28372656698170506, 0.939374366452345, 0.854...   \n",
      "16  [0.8310437003897952, 0.2965356799809107, 0.630...   \n",
      "17  [0.8437196257360502, 0.7064169325801006, 0.400...   \n",
      "18  [0.915004381857838, 0.9451554696870076, 0.7860...   \n",
      "19  [0.7981545573208623, 0.775890817271543, 0.8878...   \n",
      "\n",
      "                                           Distances2  \n",
      "0   [0.0, 0.8920946461423803, 0.9111583692162425, ...  \n",
      "1   [0.8920946461423803, 0.0, 0.868071728481023, 0...  \n",
      "2   [0.9111583692162425, 0.868071728481023, 0.0, 0...  \n",
      "3   [0.9303243886977073, 0.9012964853346812, 0.929...  \n",
      "4   [0.8305534058114642, 0.984841554252919, 0.9845...  \n",
      "5   [0.1569585265076905, 0.9674958082238044, 0.976...  \n",
      "6   [0.8908275506718375, 0.21763705379570808, 0.87...  \n",
      "7   [0.9451993394262271, 0.9399668170641375, 0.299...  \n",
      "8   [1.0424805843806029, 0.9690855439938849, 0.791...  \n",
      "9   [0.9077921663552985, 0.9997940697687624, 1.167...  \n",
      "10  [0.1459562983534376, 0.9855222458478783, 0.971...  \n",
      "11  [0.93867503668465, 0.14480168404249782, 0.8719...  \n",
      "12  [0.8890396220334488, 0.9802471146116073, 0.142...  \n",
      "13  [0.9319542874799351, 0.9691176205841107, 1.049...  \n",
      "14  [0.8071817414716174, 1.0426440244513682, 1.155...  \n",
      "15  [0.39191542857312545, 1.1313555184269872, 1.14...  \n",
      "16  [1.0112069848944372, 0.2948120191066481, 0.998...  \n",
      "17  [0.9967501005899666, 0.9108124571825172, 0.507...  \n",
      "18  [1.1627105926627086, 1.0259684397491895, 1.085...  \n",
      "19  [1.221031035630705, 0.9674847756829803, 1.2042...  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Calculate pairwise distances using the full DataFrame\n",
    "if \"Character\" in characters_df.columns:\n",
    "    characters_df[\"Distances1\"] = calculate_pairwise_distances(characters_df[\"Character\"].tolist(), model=model1)\n",
    "    characters_df[\"Distances2\"] = calculate_pairwise_distances(characters_df[\"Character\"].tolist(), model=model2)\n",
    "\n",
    "# Display updated DataFrame with distances\n",
    "print(characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_similarity(df, similarity_col):\n",
    "    avg_within_series = {}\n",
    "    avg_between_series = {}\n",
    "\n",
    "    # Group by Series and calculate averages within each group\n",
    "    grouped = df.groupby('Series')\n",
    "\n",
    "    for name, group in grouped:\n",
    "        # Flatten the list of lists for within-series calculations\n",
    "        all_similarities_within = [sim for sublist in group[similarity_col].tolist() for sim in sublist]\n",
    "        avg_within_series[name] = np.mean(all_similarities_within)\n",
    "\n",
    "        # Calculate averages with other series\n",
    "        other_groups = df[df['Series'] != name]\n",
    "\n",
    "        all_similarities_between = []\n",
    "        for _, other_group in other_groups.groupby('Series'):\n",
    "            all_similarities_between.extend([sim for sublist in other_group[similarity_col].tolist() for sim in sublist])\n",
    "        \n",
    "        avg_between_series[name] = np.mean(all_similarities_between) if all_similarities_between else 0\n",
    "\n",
    "    return avg_within_series, avg_between_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate average similarities using both models\n",
    "avg_within_1, avg_between_1 = calculate_average_similarity(characters_df, \"Distances1\")\n",
    "avg_within_2, avg_between_2 = calculate_average_similarity(characters_df, \"Distances2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_matrix(avg_within, avg_between):\n",
    "    series_names = list(avg_within.keys())\n",
    "    \n",
    "    # Initialize a square matrix with zeros\n",
    "    similarity_matrix = np.zeros((len(series_names), len(series_names)))\n",
    "\n",
    "    # Fill diagonal with within-series averages\n",
    "    for i in range(len(series_names)):\n",
    "        similarity_matrix[i][i] = avg_within[series_names[i]]\n",
    "\n",
    "    # Fill off-diagonal with between-series averages\n",
    "    for i in range(len(series_names)):\n",
    "        for j in range(len(series_names)):\n",
    "            if i != j:\n",
    "                similarity_matrix[i][j] = avg_between[series_names[j]]\n",
    "\n",
    "    return pd.DataFrame(similarity_matrix, index=series_names, columns=series_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix Model 1:\n",
      "           DS9       ENT       TNG       TOS       VOY\n",
      "DS9  0.672919  0.644596  0.646871  0.644426  0.640239\n",
      "ENT  0.634404  0.632154  0.646871  0.644426  0.640239\n",
      "TNG  0.634404  0.644596  0.623053  0.644426  0.640239\n",
      "TOS  0.634404  0.644596  0.646871  0.632832  0.640239\n",
      "VOY  0.634404  0.644596  0.646871  0.644426  0.649578\n",
      "Similarity Matrix Model 2:\n",
      "           DS9       ENT       TNG       TOS       VOY\n",
      "DS9  0.860263  0.845245  0.838786  0.844609  0.827370\n",
      "ENT  0.831916  0.806946  0.838786  0.844609  0.827370\n",
      "TNG  0.831916  0.845245  0.832780  0.844609  0.827370\n",
      "TOS  0.831916  0.845245  0.838786  0.809490  0.827370\n",
      "VOY  0.831916  0.845245  0.838786  0.844609  0.878447\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create similarity matrices for both models\n",
    "similarity_matrix_model_1 = create_similarity_matrix(avg_within_1, avg_between_1)\n",
    "similarity_matrix_model_2 = create_similarity_matrix(avg_within_2, avg_between_2)\n",
    "\n",
    "# Display matrices\n",
    "print(\"Similarity Matrix Model 1:\\n\", similarity_matrix_model_1)\n",
    "print(\"Similarity Matrix Model 2:\\n\", similarity_matrix_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison:\n",
    "\n",
    "Model 1: The values are generally lower than those in Model 2, suggesting that this model may not differentiate as effectively between characters across different series.\n",
    "\n",
    "Model 2: Higher similarity values indicate stronger relationships or contextual similarities among character pairs, which might suggest that this model captures character relationships more effectively.\n",
    "\n",
    "Relative Differentiation Between Models:\n",
    "If you compare specific pairwise similarities (e.g., DS9 vs. TNG), you may notice that the differences in similarity scores between the two models can be quite pronounced.\n",
    "\n",
    "In Model 1, similarities may not vary significantly across shows; however, in Model 2, there appears to be a clearer distinction among them.\n",
    "\n",
    "Consistent Patterns Across Shows:\n",
    "\n",
    "For both models, certain series have similar patterns of relationship with others. For instance, DS9 seems to maintain relatively high similarity scores with other series in both models but even more so in Model 2.\n",
    "\n",
    "The differences among shows might reflect how often characters interact or share similar themes and contexts.\n",
    "\n",
    "Diagonal vs. Off-Diagonal Values:\n",
    "\n",
    "In both matrices, diagonal values (representing average similarities within the same show) are typically higher than off-diagonal values (representing average similarities between different shows). This is expected since characters within the same show often share more context and dialogue.\n",
    "\n",
    "However, in Model 2, there is a notable difference between diagonal and off-diagonal values, indicating that it can differentiate better between characters of different shows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "# Repeat task for for the role-column, which contains information of the role the characters represent in the tv show. \n",
    "\n",
    "# Again, compare the inner vs. outer similarities within these groups. Which model works better for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Character Series           Roles  \\\n",
      "0     archer    ENT        Captains   \n",
      "1       kirk    TOS        Captains   \n",
      "2     picard    TNG        Captains   \n",
      "3      sisko    DS9        Captains   \n",
      "4    janeway    VOY        Captains   \n",
      "5     tucker    ENT       Engineers   \n",
      "6      scott    TOS       Engineers   \n",
      "7    laforge    TNG       Engineers   \n",
      "8     obrien    DS9       Engineers   \n",
      "9     torres    VOY       Engineers   \n",
      "10      tpol    ENT  First Officers   \n",
      "11     spock    TOS  First Officers   \n",
      "12     riker    TNG  First Officers   \n",
      "13      kira    DS9  First Officers   \n",
      "14  chakotay    VOY  First Officers   \n",
      "15      trip    ENT       Nicknames   \n",
      "16    scotty    TOS       Nicknames   \n",
      "17   beverly    TNG       Nicknames   \n",
      "18    jadzia    DS9       Nicknames   \n",
      "19     harry    VOY       Nicknames   \n",
      "\n",
      "                                           Distances1  \\\n",
      "0   [0.0, 0.7208909048931522, 0.6895365561243276, ...   \n",
      "1   [0.7208909048931522, 0.0, 0.602005696738748, 0...   \n",
      "2   [0.6895365561243276, 0.602005696738748, 0.0, 0...   \n",
      "3   [0.7165056724639904, 0.7498883896616257, 0.682...   \n",
      "4   [0.581562694894215, 0.751643416771538, 0.73235...   \n",
      "5   [0.14767356552072242, 0.8188708407854127, 0.75...   \n",
      "6   [0.7091926809124438, 0.23459872804579274, 0.54...   \n",
      "7   [0.6726415100968977, 0.6631738705920972, 0.297...   \n",
      "8   [0.8335620431979512, 0.7771443828518045, 0.598...   \n",
      "9   [0.6813261979135298, 0.8037809152348383, 0.850...   \n",
      "10  [0.13605530235395358, 0.7811482818980454, 0.69...   \n",
      "11  [0.769839280293052, 0.15935224666960512, 0.606...   \n",
      "12  [0.6919519501710039, 0.7268224120439766, 0.138...   \n",
      "13  [0.7672236374444863, 0.8072818707614484, 0.778...   \n",
      "14  [0.6025535832402734, 0.8326290161276206, 0.835...   \n",
      "15  [0.28372656698170506, 0.939374366452345, 0.854...   \n",
      "16  [0.8310437003897952, 0.2965356799809107, 0.630...   \n",
      "17  [0.8437196257360502, 0.7064169325801006, 0.400...   \n",
      "18  [0.915004381857838, 0.9451554696870076, 0.7860...   \n",
      "19  [0.7981545573208623, 0.775890817271543, 0.8878...   \n",
      "\n",
      "                                           Distances2  \\\n",
      "0   [0.0, 0.8920946461423803, 0.9111583692162425, ...   \n",
      "1   [0.8920946461423803, 0.0, 0.868071728481023, 0...   \n",
      "2   [0.9111583692162425, 0.868071728481023, 0.0, 0...   \n",
      "3   [0.9303243886977073, 0.9012964853346812, 0.929...   \n",
      "4   [0.8305534058114642, 0.984841554252919, 0.9845...   \n",
      "5   [0.1569585265076905, 0.9674958082238044, 0.976...   \n",
      "6   [0.8908275506718375, 0.21763705379570808, 0.87...   \n",
      "7   [0.9451993394262271, 0.9399668170641375, 0.299...   \n",
      "8   [1.0424805843806029, 0.9690855439938849, 0.791...   \n",
      "9   [0.9077921663552985, 0.9997940697687624, 1.167...   \n",
      "10  [0.1459562983534376, 0.9855222458478783, 0.971...   \n",
      "11  [0.93867503668465, 0.14480168404249782, 0.8719...   \n",
      "12  [0.8890396220334488, 0.9802471146116073, 0.142...   \n",
      "13  [0.9319542874799351, 0.9691176205841107, 1.049...   \n",
      "14  [0.8071817414716174, 1.0426440244513682, 1.155...   \n",
      "15  [0.39191542857312545, 1.1313555184269872, 1.14...   \n",
      "16  [1.0112069848944372, 0.2948120191066481, 0.998...   \n",
      "17  [0.9967501005899666, 0.9108124571825172, 0.507...   \n",
      "18  [1.1627105926627086, 1.0259684397491895, 1.085...   \n",
      "19  [1.221031035630705, 0.9674847756829803, 1.2042...   \n",
      "\n",
      "                                      Role_Distances1  \\\n",
      "0   [0.0, 0.7208909048931522, 0.6895365561243276, ...   \n",
      "1   [0.7208909048931522, 0.0, 0.602005696738748, 0...   \n",
      "2   [0.6895365561243276, 0.602005696738748, 0.0, 0...   \n",
      "3   [0.7165056724639904, 0.7498883896616257, 0.682...   \n",
      "4   [0.581562694894215, 0.751643416771538, 0.73235...   \n",
      "5   [0.14767356552072242, 0.8188708407854127, 0.75...   \n",
      "6   [0.7091926809124438, 0.23459872804579274, 0.54...   \n",
      "7   [0.6726415100968977, 0.6631738705920972, 0.297...   \n",
      "8   [0.8335620431979512, 0.7771443828518045, 0.598...   \n",
      "9   [0.6813261979135298, 0.8037809152348383, 0.850...   \n",
      "10  [0.13605530235395358, 0.7811482818980454, 0.69...   \n",
      "11  [0.769839280293052, 0.15935224666960512, 0.606...   \n",
      "12  [0.6919519501710039, 0.7268224120439766, 0.138...   \n",
      "13  [0.7672236374444863, 0.8072818707614484, 0.778...   \n",
      "14  [0.6025535832402734, 0.8326290161276206, 0.835...   \n",
      "15  [0.28372656698170506, 0.939374366452345, 0.854...   \n",
      "16  [0.8310437003897952, 0.2965356799809107, 0.630...   \n",
      "17  [0.8437196257360502, 0.7064169325801006, 0.400...   \n",
      "18  [0.915004381857838, 0.9451554696870076, 0.7860...   \n",
      "19  [0.7981545573208623, 0.775890817271543, 0.8878...   \n",
      "\n",
      "                                      Role_Distances2  \n",
      "0   [0.0, 0.8920946461423803, 0.9111583692162425, ...  \n",
      "1   [0.8920946461423803, 0.0, 0.868071728481023, 0...  \n",
      "2   [0.9111583692162425, 0.868071728481023, 0.0, 0...  \n",
      "3   [0.9303243886977073, 0.9012964853346812, 0.929...  \n",
      "4   [0.8305534058114642, 0.984841554252919, 0.9845...  \n",
      "5   [0.1569585265076905, 0.9674958082238044, 0.976...  \n",
      "6   [0.8908275506718375, 0.21763705379570808, 0.87...  \n",
      "7   [0.9451993394262271, 0.9399668170641375, 0.299...  \n",
      "8   [1.0424805843806029, 0.9690855439938849, 0.791...  \n",
      "9   [0.9077921663552985, 0.9997940697687624, 1.167...  \n",
      "10  [0.1459562983534376, 0.9855222458478783, 0.971...  \n",
      "11  [0.93867503668465, 0.14480168404249782, 0.8719...  \n",
      "12  [0.8890396220334488, 0.9802471146116073, 0.142...  \n",
      "13  [0.9319542874799351, 0.9691176205841107, 1.049...  \n",
      "14  [0.8071817414716174, 1.0426440244513682, 1.155...  \n",
      "15  [0.39191542857312545, 1.1313555184269872, 1.14...  \n",
      "16  [1.0112069848944372, 0.2948120191066481, 0.998...  \n",
      "17  [0.9967501005899666, 0.9108124571825172, 0.507...  \n",
      "18  [1.1627105926627086, 1.0259684397491895, 1.085...  \n",
      "19  [1.221031035630705, 0.9674847756829803, 1.2042...  \n"
     ]
    }
   ],
   "source": [
    "#Step 1: Calculate Pairwise Distances Based on Roles\n",
    "\n",
    "# Calculate pairwise distances using the Role column\n",
    "if \"Roles\" in characters_df.columns:\n",
    "    characters_df[\"Role_Distances1\"] = calculate_pairwise_distances(characters_df[\"Character\"].tolist(), model=model1)\n",
    "    characters_df[\"Role_Distances2\"] = calculate_pairwise_distances(characters_df[\"Character\"].tolist(), model=model2)\n",
    "\n",
    "# Display updated DataFrame with distances based on roles\n",
    "print(characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate Average Similarities Within and Between Roles\n",
    "# Next, define a function similar to what you did in Task 4 but adjusted for roles:\n",
    "\n",
    "def calculate_average_similarity_by_role(df, similarity_col):\n",
    "    avg_within_role = {}\n",
    "    avg_between_role = {}\n",
    "\n",
    "    # Group by Role and calculate averages within each group\n",
    "    grouped = df.groupby('Roles')\n",
    "\n",
    "    for name, group in grouped:\n",
    "        # Flatten the list of lists for within-role calculations\n",
    "        all_similarities_within = [sim for sublist in group[similarity_col].tolist() for sim in sublist]\n",
    "        avg_within_role[name] = np.mean(all_similarities_within) if all_similarities_within else 0\n",
    "\n",
    "        # Calculate averages with other roles\n",
    "        other_groups = df[df['Roles'] != name]\n",
    "\n",
    "        all_similarities_between = []\n",
    "        for _, other_group in other_groups.groupby('Roles'):\n",
    "            all_similarities_between.extend([sim for sublist in other_group[similarity_col].tolist() for sim in sublist])\n",
    "        \n",
    "        avg_between_role[name] = np.mean(all_similarities_between) if all_similarities_between else 0\n",
    "\n",
    "    return avg_within_role, avg_between_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate average similarities using both models based on Roles\n",
    "avg_within_roles_1, avg_between_roles_1 = calculate_average_similarity_by_role(characters_df, \"Role_Distances1\")\n",
    "avg_within_roles_2, avg_between_roles_2 = calculate_average_similarity_by_role(characters_df, \"Role_Distances2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role Similarity Matrix Model 1:\n",
      "                 Captains  Engineers  First Officers  Nicknames\n",
      "Captains        0.635921   0.650206         0.64263   0.631423\n",
      "Engineers       0.644169   0.617810         0.64263   0.631423\n",
      "First Officers  0.644169   0.650206         0.64054   0.631423\n",
      "Nicknames       0.644169   0.650206         0.64263   0.674159\n",
      "Role Similarity Matrix Model 2:\n",
      "                 Captains  Engineers  First Officers  Nicknames\n",
      "Captains        0.834309   0.851137        0.838587   0.821940\n",
      "Engineers       0.838677   0.796931        0.838587   0.821940\n",
      "First Officers  0.838677   0.851137        0.834579   0.821940\n",
      "Nicknames       0.838677   0.851137        0.838587   0.884522\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create Similarity Matrices Based on Roles\n",
    "\n",
    "# Create similarity matrices for both models based on Roles\n",
    "role_similarity_matrix_model_1 = create_similarity_matrix(avg_within_roles_1, avg_between_roles_1)\n",
    "role_similarity_matrix_model_2 = create_similarity_matrix(avg_within_roles_2, avg_between_roles_2)\n",
    "\n",
    "# Display matrices\n",
    "print(\"Role Similarity Matrix Model 1:\\n\", role_similarity_matrix_model_1)\n",
    "print(\"Role Similarity Matrix Model 2:\\n\", role_similarity_matrix_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Comparison for Task 5\n",
    "\n",
    "Model 1:\n",
    "The similarity scores in Model 1 are lower overall compared to those in Model 2.\n",
    "The distinctions between different roles are less pronounced, indicating that this model may not effectively differentiate characters based on their roles.\n",
    "\n",
    "Model 2:\n",
    "The similarity scores in Model 2 are consistently higher across all role comparisons.\n",
    "There are clearer distinctions between the average similarities of different roles, suggesting that this model captures contextual relationships more effectively.\n",
    "For example, the highest score (0.884522) for \"Nicknames\" indicates strong contextual relationships among characters with that role.\n",
    "\n",
    "Conclusion\n",
    "Model 2 works better for this task of differentiating characters based on their roles within the TV shows. The higher cosine similarity values and clearer differentiation among roles suggest that Model 2 is better at capturing the nuances of character interactions as influenced by their assigned roles.\n",
    "\n",
    "Implications\n",
    "This implies that when analyzing character relationships within a franchise like Star Trek, using a Word2Vec model with a larger window size (as seen in your second model) allows for capturing broader contextual information from dialogues and interactions across episodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
